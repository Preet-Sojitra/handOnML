{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b95104-bc2d-4d4b-b221-a1bfa1117209",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16833ab2-1ec5-4453-878f-bc6561934634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 21:38:30.312578: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-11 21:38:30.353650: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-11 21:38:30.354069: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 21:38:31.353767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb398cd-51d0-41de-8cda-520d2ae61bfe",
   "metadata": {},
   "source": [
    "## The Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c71574-1510-4009-8a12-81aad35c7622",
   "metadata": {},
   "source": [
    "The whole Data api revolves around the concept of *datasets*. Usually, we will use datasets that gradually read data from disk, but from simplicity let's create a dataset entirely in RAM using `tf.data.Dataset.from_tensor_slices()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a2f9ed-7d28-4822-9dec-8f136cc2c95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10) # any data tensor\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c0f07-41c7-4e0b-ba1b-b4aadd3524bc",
   "metadata": {},
   "source": [
    "The `from_tensor_slices()` function takes a tensor and creates a `tf.data.Dataset` whose elements are all slices of `X` (along the first dimension), so this dataset contains 10 items: tensors 0, 1, 2,...,9. In this case we would have obtained the same dataset if we had used `tf.data.Dataset.range(10)`\n",
    "\n",
    "We can simply iterate over a dataset's items like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "351abba5-18ff-4d3b-8413-dbc8b5ddbf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6103af0-3e84-4ca3-8396-f8ce61558b86",
   "metadata": {},
   "source": [
    "### Chaining Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a2a8b-c918-4953-b4d4-832f2f9f4918",
   "metadata": {},
   "source": [
    "Once we have dataset, we can apply all sort of transformations to it by calling its transformation methods. Each method returns a new dataset, so we can chain transformations like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9092178d-d75f-47e3-8f77-c738f53d5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907b2c4-4f67-4d4d-876a-e6331fc9d4dc",
   "metadata": {},
   "source": [
    "In this example, we first call `repeat()` method on the original dataset, and it returns a new dataset that will repeat the items in the original dataset three times. Then we call the `batch()` method on this new dataset, and again creates a new dataset. This one will group the items of the previous dataset in batches of seven items. Finally, we can iterate over the items of this final dataset.\n",
    "\n",
    "As we can see, the `batch()` method had to output a final batch of size two instead of seven, but we can call it with a `drop_remainder=True` if we want it to drop this final batch so that all batches have the exact same size. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda4554f-5ed1-4c3d-b60a-d241e9a69966",
   "metadata": {},
   "source": [
    "We can also transform the items by calling the `map()` method. For ex., this creates a new dataset with all items doubled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d5af453-eae7-42d9-a4c7-6614c59ffbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
      "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
      "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: x*2)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1ab84-28aa-4910-a9cc-13da9397a2ba",
   "metadata": {},
   "source": [
    "This function is the one we will call to apply any preprocessing we want to our data. Sometimes this will include computations that can be quite intensive, such as reshaping or rotating an image, so we will usually want to spawn multiple threads to speed things up: it's as simple as setting the\n",
    "`num_parallel_calls` argument. \n",
    "\n",
    "**NOTE**:\n",
    "The function we pass to the `map()` must be convertible to TF Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd2cbf-d30f-4fd1-9a25-2e892ad11a24",
   "metadata": {},
   "source": [
    "While `map()` method applies transformation to each item, the `apply()` method applies a transformation to the dataset as a whole. \n",
    "\n",
    "For ex., the `unbatch()` function to the dataset will create a new dataset where each item will be single-integer tensor instead of batch of seven integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "680dcddc-6931-4543-8f5c-eedff886978f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.unbatch()\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae0e3a-7246-465a-949f-a7e45ead069b",
   "metadata": {},
   "source": [
    "It is also possible to simply filter the dataset using the `filter()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "940e787c-458c-4d32-968e-56be7edd2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x < 10)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012fb54-73b2-44f9-b467-b48459356787",
   "metadata": {},
   "source": [
    "We will often want to look at just few items from a dataset. We can use `take()` method for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfeb3cca-4471-49cf-b0ef-e25a32b15797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f3cd4-58a6-48df-b2d8-bb24df35675e",
   "metadata": {},
   "source": [
    "### Shuffling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c0074-5406-4775-8c18-35dd901bca00",
   "metadata": {},
   "source": [
    "Gradient Descent works best when the instances in the training set are independent and identically distributed. A simple way to ensure this is to shuffle the instances using the `shuffle()` method.  For ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4238aa6e-3cc6-478d-8b0b-d205971fbf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, 3 times\n",
    "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7) # we must specify the buffer size, and it is imp to make it large enough, or else shuffling will not be very effective. \n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c2a72-b363-4773-ae3a-7ba7e21f2638",
   "metadata": {},
   "source": [
    "**TIP:**\n",
    "\n",
    "If we call `repeat()` on a shuffled dataset, by default it will generate a new order at every iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d04bc1-80b6-4e85-b1b5-aeaaecc810e4",
   "metadata": {},
   "source": [
    "For large datasets that does not fit in memory, this simple shuffling-buffer approach may not be sufficient, since the buffer will be small compared to dataset. One solution is to shuffle the source data itself. This will definitely improve the shuffling a lot. Even if the data is shuffled, we usually want to shuffle it more. To shuffle the instances some more, a common approach is to split source data into multiple files, then read them in random order during training. However, instances located in same file will still end up close together. To avoid this, we can pick multiple files randomly and read them simultaneously, interleaving records. Then on top of that we can add a shuffling buffer using `shuffle()` method. Let's see how it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595005da-b980-4b7c-9a0e-10d32dade3a0",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing California dataset. We will first load it, split it intro training, validation and test set and finally we scale it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3570effe-b24f-4cbb-9937-30afccf8ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target.reshape(-1,1),\n",
    "                                                             random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87d06b-8908-4118-af5e-4867594083de",
   "metadata": {},
   "source": [
    "For very large dataset that does not fit in memory, we will typically need to split it into many files first, then have TF read these files in parallel. To demonstrate this, let's start by splitting the housing dataset and save it in 20 csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dec3e5-1838-482b-9c15-1ecff79666b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(os.curdir, \"datasets\", \"california_housing\")\n",
    "    # print(housing_dir)\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "    \n",
    "    file_paths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        file_paths.append(part_csv)\n",
    "        with open (part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                \"\"\"\n",
    "                Python repr() function returns a printable representation of the object by converting\n",
    "                that object to a string.\n",
    "                \"\"\"\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9df56a-d07f-4255-9480-a72133ea3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423f2f23-a409-43bf-80e7-0bc766c90b0d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/california_housing/my_train_00.csv',\n",
       " './datasets/california_housing/my_train_01.csv',\n",
       " './datasets/california_housing/my_train_02.csv',\n",
       " './datasets/california_housing/my_train_03.csv',\n",
       " './datasets/california_housing/my_train_04.csv',\n",
       " './datasets/california_housing/my_train_05.csv',\n",
       " './datasets/california_housing/my_train_06.csv',\n",
       " './datasets/california_housing/my_train_07.csv',\n",
       " './datasets/california_housing/my_train_08.csv',\n",
       " './datasets/california_housing/my_train_09.csv',\n",
       " './datasets/california_housing/my_train_10.csv',\n",
       " './datasets/california_housing/my_train_11.csv',\n",
       " './datasets/california_housing/my_train_12.csv',\n",
       " './datasets/california_housing/my_train_13.csv',\n",
       " './datasets/california_housing/my_train_14.csv',\n",
       " './datasets/california_housing/my_train_15.csv',\n",
       " './datasets/california_housing/my_train_16.csv',\n",
       " './datasets/california_housing/my_train_17.csv',\n",
       " './datasets/california_housing/my_train_18.csv',\n",
       " './datasets/california_housing/my_train_19.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7046dd4-c59b-4c17-a095-e1dca664ec3f",
   "metadata": {},
   "source": [
    "Okay, now let's look at the first few lines of one of these csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3ace728-0e7e-447a-92a7-e3022cb59058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329e7a8-b218-4111-98ff-3ecda130b0aa",
   "metadata": {},
   "source": [
    "Or in text mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00a28eef-aa72-495f-8934-5c9d38cd3c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
     ]
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09b09c-1e9f-427a-87ca-3f51bb4c010a",
   "metadata": {},
   "source": [
    "#### Interleaving lines from multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed97b32-ae3a-4dec-8cee-b732da29e88e",
   "metadata": {},
   "source": [
    "Now let's create a dataset containing only these train file paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88b1f23a-f040-4632-8235-8af55f505b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db970b2-6713-4519-bb24-ca46b5e44dcf",
   "metadata": {},
   "source": [
    "By defult `list_files()` returns a dataset that shuffles the file paths. In general this is good, but we can set `shuffle=False` if we do not want that for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d679da-3b2e-475c-a71c-0303283f8a89",
   "metadata": {},
   "source": [
    "Now we can call the `interleave()` method to read from five files at a time and interleave thier lines (skipping the first line of each file, which is header row, using the `skip()` method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b730126-d495-49ce-9b57-48ea36553e96",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'./datasets/california_housing/my_train_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_16.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_17.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_14.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_10.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_12.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_19.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_09.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_13.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_15.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_11.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_18.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'./datasets/california_housing/my_train_08.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for filepath in filepath_dataset:\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5819c723-bea9-469a-aac1-b13c2d9a5770",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5\n",
    "\"\"\"\n",
    "The tf.data.TextLineDataset loads text from text files and creates a dataset where each line of the files becomes an element of the dataset.\n",
    "\"\"\"\n",
    "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                  cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fef876-2af2-4c02-9879-54d4979689a2",
   "metadata": {},
   "source": [
    "The `interleave()` method will create a dataset that will pull five file path from the `filepath_dataset`, and for each one it will call the function we gave it (a lambda in this example), to create a new dataset (in this case a `TextLineDataset`). \n",
    "\n",
    "To be clear, at this stage there will be seven datasets in all: the filepath dataset, the interleave dataset, and the five `TextLineDataset` created internally by the interleave dataset. When we interate over the interleave dataset, it will cycle through these five `TextLineDatasets`, reading one line at a time from each until all datasets are out of items. Then it will get next five file paths from the `filepath_datasets` and interleave them the same way, and so on until it runs out of file paths. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24895a8-abf3-411c-8a3c-6092b5f890e0",
   "metadata": {},
   "source": [
    "**TIP:**\n",
    "\n",
    "For interleaving to work best, it is preferable to have files of identical lengths; otherwise the ends of the longest files will not be interleaved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd5d81-e905-4b08-8e06-5f8476122e79",
   "metadata": {},
   "source": [
    "By default, `interleave()` does not use parallelism; it just reads one line at a time from each line, sequentially. If we want it to actually read files in parallel, we can set the `num_parallel_calls` argument to the number of threads we want. We can even set  it to `tf.data.AUTOTUNE` to make tf choose the right number of threads dynamically based on the available CPU. \n",
    "\n",
    "Let's look at what the dataset contains now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "598228f4-327c-44e9-8222-7bdacd2975be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n",
      "b'3.226,52.0,5.372469635627531,0.9473684210526315,1157.0,2.3421052631578947,37.96,-121.31,1.076'\n",
      "b'4.2708,45.0,5.121387283236994,0.953757225433526,492.0,2.8439306358381504,37.48,-122.19,2.67'\n",
      "b'3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442'\n",
      "b'3.0217,22.0,4.983870967741935,1.1008064516129032,615.0,2.4798387096774195,38.76,-120.6,1.069'\n"
     ]
    }
   ],
   "source": [
    "for line in dataset.take(5):\n",
    "    print(line.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1697b8f-59ce-4a16-979b-8973d214c9a5",
   "metadata": {},
   "source": [
    "Looks good! But as we can see, these are just byte strings; we need to parse them and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05cfecc2-8468-4895-95e0-f679137a6b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=1>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.0>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=3.0>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'4'>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_defaults = [0, np.nan, tf.constant(np.nan, dtype=np.float64), \"Hello\", tf.constant([])]\n",
    "\"\"\"\n",
    "tf.io.decode_csv : Convert CSV records to tensors. Each column maps to one tensor.\n",
    "\n",
    "record_defaults = A list of Tensor objects with specific types. \n",
    "\"\"\"\n",
    "parsed_fields = tf.io.decode_csv(\"1,2,3,4,5\", record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de765807-6d12-429b-8137-55c7c5ca5933",
   "metadata": {},
   "source": [
    "Notice that in above, field 4 is interpreted as string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0c8219a7-2aa1-4854-a52b-da2845d2b50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=nan>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=nan>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'Hello'>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=5.0>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_fields = tf.io.decode_csv(\",,,,5\", record_defaults)\n",
    "parsed_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bd9e9-0097-4055-9821-44ee55775664",
   "metadata": {},
   "source": [
    "Notice that all the missing values are replaced by default values.\n",
    "\n",
    "Also the number of fields should match exactly the number of fields in record_defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780ac4f-99d0-4b1f-bab2-636b8cbb11fb",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a64c32-bb54-4ba6-9339-61bdbe3abc9f",
   "metadata": {},
   "source": [
    "Now let's implement a function that perfroms this preprocessing (parsing the csv and scaling them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fde3a569-e8a1-41ad-afc1-bc1a4a59d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[-1]\n",
    "\n",
    "def preprocess(line):\n",
    "    defaults = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defaults)\n",
    "    # print(fields)\n",
    "    # fields is a list of tensors where each tensor contains one feature value. So we need to use tf.stack to make it to array\n",
    "    x = tf.stack(fields[:-1])\n",
    "    # print(x)\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x-X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "16d00b13-2f6f-41a4-adb1-91c38edf4b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.15159765,  1.8491895 ,  0.09624147, -0.22151624, -0.66828614,\n",
       "        -0.23549314, -0.89780813,  0.6368871 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3.215], dtype=float32)>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73, -118.31,3.215')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb532b-3cb9-434e-9191-3337ec16376e",
   "metadata": {},
   "source": [
    "Looks good! We can now apply the function to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e0e07-1477-49ca-b88c-41f33703dbf4",
   "metadata": {},
   "source": [
    "### Putting EveryThing Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb9464-e5e2-40aa-901f-33fe77661da7",
   "metadata": {},
   "source": [
    "To make the code reusable, let's put together everything in small helper function: it will create and return a dataset that will efficiently load California housing dataset from multiple CSV files, preprocess it, shuffle it and optionally repeat it, and batch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cdc1eae-ffdb-43b1-ac5f-3735e65b6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5, n_read_threads=None,\n",
    "                       shuffle_buffer_size=10000, n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d752e4-2548-4be3-8d21-c5d97a658038",
   "metadata": {},
   "source": [
    "The last line `prefetch(1)` is important for performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad211573-7b61-4e1d-a4ac-0ce534dd0ce1",
   "metadata": {},
   "source": [
    "### Prefetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461354b4-9580-4822-92ab-d5968999005e",
   "metadata": {},
   "source": [
    "By calling `prefetch(1)` at the end, we are creating a dataset that will do its best to always be one batch ahead. (In general prefetching one batch is fine, but in some case we may need few more. We can always let tf decide on its own by passign `tf.data.AUTOTUNE`). In other words, while our training algorithm is working on one batch, the dataset will already be working in parallel on getting the next batch ready (e.g., reading the data from disk and preprocessing it). This can improve performace dramatically. If we also ensure that loading and preprocessing are multithreaded, we can exploit multiple cores on the CPU. \n",
    "\n",
    "If dataset is small enough to fit in memory, we can significantly speed up training by using the dataset's `cache()` method to cache its content to RAM. We should generally do this after loading and preprocessing data, but before shuffling, repeating, batching and prefetching. This way, each instance will only be read and preprocessed once (instead once per epoch), but the data will still be shuffled differently at each epoch, and the next batch will still be prepared in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2f0d1-801b-4bdd-8d4d-be34efdbfd09",
   "metadata": {},
   "source": [
    "### Using the Dataset with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1eeb4c-9f78-4486-aa24-1cd3d73ddbd4",
   "metadata": {},
   "source": [
    "Now we have `csv_reader_dataset()` function to create a dataset for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d370ca-4c43-4284-ba8c-1f2ca4154346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = tf.Tensor(\n",
      "[[ 0.5804519  -0.20762321  0.05616303 -0.15191229  0.01343246  0.00604472\n",
      "   1.2525111  -1.3671792 ]\n",
      " [ 5.818099    1.8491895   1.1784915   0.28173092 -1.2496178  -0.3571987\n",
      "   0.7231292  -1.0023477 ]\n",
      " [-0.9253566   0.5834586  -0.7807257  -0.28213993 -0.36530012  0.27389365\n",
      "  -0.76194876  0.72684526]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.752]\n",
      " [1.313]\n",
      " [1.535]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[-0.8324941   0.6625668  -0.20741376 -0.18699841 -0.14536144  0.09635526\n",
      "   0.9807942  -0.67250353]\n",
      " [-0.62183803  0.5834586  -0.19862501 -0.3500319  -1.1437552  -0.3363751\n",
      "   1.107282   -0.8674123 ]\n",
      " [ 0.8683102   0.02970133  0.3427381  -0.29872298  0.7124906   0.28026953\n",
      "  -0.72915536  0.86178064]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[0.919]\n",
      " [1.028]\n",
      " [2.182]], shape=(3, 1), dtype=float32)\n",
      "\n",
      "X = tf.Tensor(\n",
      "[[-1.0344558   1.0581076  -0.8869343  -0.08743899  0.6157541   0.4368748\n",
      "  -0.75726473  0.64688075]\n",
      " [ 0.4675818   0.6625668   0.03120424 -0.02621728 -0.8498953  -0.11217064\n",
      "  -0.860329    0.72684526]\n",
      " [-0.75702035  0.26702586 -0.60196173 -0.07209105  0.28082678  0.36254692\n",
      "  -0.7338394   0.7768212 ]], shape=(3, 8), dtype=float32)\n",
      "y = tf.Tensor(\n",
      "[[1.364]\n",
      " [2.314]\n",
      " [1.696]], shape=(3, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = csv_reader_dataset(train_filepaths, batch_size=3)\n",
    "for X_batch, y_batch in train_set.take(3):\n",
    "    print(\"X =\", X_batch)\n",
    "    print(\"y =\", y_batch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f71a25-874f-4a77-b416-33b327ad0189",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad5f17-71de-4ebb-92c8-31c359e54d22",
   "metadata": {},
   "source": [
    "And now we can simply build and train a Keras model using these datasets (support is specific for `tf.keras`). All we need to do is pass the training and validation datasets to the `fit()` method, instead of `X_train, y_train, X_vaild` and `y_valid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a29dd009-3dcf-4794-ba62-a4a605e2e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21229f57-11db-4b71-80ef-3e77dc3bfb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14cc65a-96aa-4da3-96e0-c5cba0a56c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 2.0315 - val_loss: 3.7452\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.9367 - val_loss: 0.7827\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.7497 - val_loss: 0.8117\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.6687 - val_loss: 0.6846\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.6179 - val_loss: 0.6467\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 1s 3ms/step - loss: 0.6187 - val_loss: 0.6151\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.5609 - val_loss: 0.7972\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 1s 2ms/step - loss: 0.5372 - val_loss: 0.5258\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.5180 - val_loss: 0.5510\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 1s 4ms/step - loss: 0.5200 - val_loss: 0.4858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5f045935d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train)//batch_size, epochs=10,\n",
    "         validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f3d60a-e524-4973-9bcb-1871e7fa2be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 1ms/step - loss: 0.4921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49213576316833496"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c559513-9fcc-4ca9-aa7e-1d8856c745ba",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.7322209 ],\n",
       "       [1.3085666 ],\n",
       "       [1.5255079 ],\n",
       "       [1.0248382 ],\n",
       "       [2.5808408 ],\n",
       "       [2.2871757 ],\n",
       "       [1.7916274 ],\n",
       "       [4.3145485 ],\n",
       "       [2.206674  ],\n",
       "       [2.4540796 ],\n",
       "       [2.491219  ],\n",
       "       [2.857857  ],\n",
       "       [2.7704601 ],\n",
       "       [2.5426204 ],\n",
       "       [0.67148834],\n",
       "       [2.1122987 ],\n",
       "       [3.4075441 ],\n",
       "       [2.0837922 ],\n",
       "       [5.348416  ],\n",
       "       [1.9640238 ],\n",
       "       [3.9412053 ],\n",
       "       [1.339951  ],\n",
       "       [2.236424  ],\n",
       "       [1.6961956 ],\n",
       "       [2.6966777 ],\n",
       "       [1.5503691 ],\n",
       "       [1.9002333 ],\n",
       "       [2.3937144 ],\n",
       "       [3.0539567 ],\n",
       "       [1.2766786 ],\n",
       "       [2.2559    ],\n",
       "       [1.3738415 ],\n",
       "       [2.22063   ],\n",
       "       [0.91933674],\n",
       "       [5.45888   ],\n",
       "       [2.0175803 ],\n",
       "       [1.8049254 ],\n",
       "       [2.058518  ],\n",
       "       [1.6453042 ],\n",
       "       [3.0500243 ],\n",
       "       [1.1761464 ],\n",
       "       [1.2705905 ],\n",
       "       [4.044486  ],\n",
       "       [2.1326566 ],\n",
       "       [1.2013569 ],\n",
       "       [3.055455  ],\n",
       "       [2.1411066 ],\n",
       "       [1.0861909 ],\n",
       "       [1.3554629 ],\n",
       "       [1.2244564 ],\n",
       "       [2.0859795 ],\n",
       "       [2.509807  ],\n",
       "       [2.53593   ],\n",
       "       [1.5357313 ],\n",
       "       [2.328605  ],\n",
       "       [1.1619896 ],\n",
       "       [2.4998362 ],\n",
       "       [1.2269835 ],\n",
       "       [1.3960061 ],\n",
       "       [4.6563287 ],\n",
       "       [4.258176  ],\n",
       "       [3.5505226 ],\n",
       "       [2.5182273 ],\n",
       "       [1.7964044 ],\n",
       "       [2.6224167 ],\n",
       "       [1.0477208 ],\n",
       "       [1.4842416 ],\n",
       "       [3.1475916 ],\n",
       "       [0.9972979 ],\n",
       "       [2.1971037 ],\n",
       "       [1.902704  ],\n",
       "       [1.6066481 ],\n",
       "       [1.8536577 ],\n",
       "       [2.5204687 ],\n",
       "       [1.2242396 ],\n",
       "       [1.720289  ],\n",
       "       [0.9404229 ],\n",
       "       [1.5397108 ],\n",
       "       [1.8173523 ],\n",
       "       [3.2756157 ],\n",
       "       [3.7198763 ],\n",
       "       [2.4297867 ],\n",
       "       [2.2749891 ],\n",
       "       [1.7196877 ],\n",
       "       [2.6116598 ],\n",
       "       [1.0306777 ],\n",
       "       [2.2150636 ],\n",
       "       [2.1341648 ],\n",
       "       [2.560404  ],\n",
       "       [3.1973665 ],\n",
       "       [5.440608  ],\n",
       "       [2.1385133 ],\n",
       "       [2.9516919 ],\n",
       "       [3.304295  ],\n",
       "       [4.067764  ],\n",
       "       [1.7898543 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.take(3).map(lambda X, y: X) # pretend we have 3 new instances\n",
    "model.predict(new_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701cc04f-8bbd-4193-a447-206f95d1872c",
   "metadata": {},
   "source": [
    "If we want to build our own custom training loop, we can just iterate over the training set, very naturally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afd27753-6a51-4849-b5b5-c32fa928f573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step 1810/1810"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "total_steps = n_epochs * n_steps_per_epoch\n",
    "global_step = 0\n",
    "\n",
    "for X_batch, y_batch in train_set.take(total_steps):\n",
    "    global_step += 1\n",
    "    print(f\"\\rGlobal step {global_step}/{total_steps}\", end=\"\")\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X_batch)\n",
    "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "        loss = tf.add_n([main_loss] + model.losses)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c03774-3f14-44d0-855e-14a928e581a0",
   "metadata": {},
   "source": [
    "In fact, it is even possible to create TF Function, that performs the whole training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f0928a6-26af-4db7-9682-cb41f9a63c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32, n_readers=5, n_read_threads=5,\n",
    "         shuffle_buffer_size = 10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                                  n_read_threads=n_read_threads,\n",
    "                                  shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                  n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0063c3a9-6264-4af9-a002-b713047ea25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56287a76-c1e1-4f62-9543-e5b9b48da894",
   "metadata": {},
   "source": [
    "## The TFRecord Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a4ac9-4e39-48df-8bcb-c77b1bab0f9e",
   "metadata": {},
   "source": [
    "We can easily create a TFRecord file using the `tf.io.TFRecordWriter` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e074e156-6f59-4193-8ed8-bc0831254cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is first record\")\n",
    "    f.write(b\"And this is second record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b47e74-5af1-4a2a-9841-997d63a12784",
   "metadata": {},
   "source": [
    "And we can then use a `tf.data.TFRecordDataset` to read one or more TFRecord files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea480681-f158-4bdc-a2f9-ac47763a7f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is second record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd61bb4-b712-49e5-9234-235208920fb3",
   "metadata": {},
   "source": [
    "**TIP:**\n",
    "\n",
    "By default, a `TFRecordDataset` will read files one by one, but we can make it read multiple files in parallel and interleave their records by setting `num_parallel_reads`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6562ef-c4e7-4cfe-bc6b-7a137d0b348c",
   "metadata": {},
   "source": [
    "### Compressed TFRecord Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977998e-9990-48b4-8ff6-3878a5a2f7b9",
   "metadata": {},
   "source": [
    "It can sometimes be useful to compress our TFRecord files, especially if they need to be loaded via a network connection. We can create a compressed TFRecord file by setting the `options` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f50f643-442c-45a2-8403-6c4ed01af3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(b\"This is first compressed record\")\n",
    "    f.write(b\"This is second compressed record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7446a6-146a-4960-b567-a154b5e9eda3",
   "metadata": {},
   "source": [
    "When reading a compressed TFRecord file, we need to specify the compression type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e09d7d8-4047-4df0-abad-fd7a4158c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is first compressed record', shape=(), dtype=string)\n",
      "tf.Tensor(b'This is second compressed record', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], compression_type=\"GZIP\")\n",
    "\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912596fc-4f75-4960-b812-e1b13b9a7b37",
   "metadata": {},
   "source": [
    "### A Brief Introduction to Protocol Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2ee81-00b0-45b2-9ab6-69547d8500ae",
   "metadata": {},
   "source": [
    "To illustrate the basics, let's look at a simple example that uses the access classes generated for the `Person` protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91be8ab2-93bf-4550-8240-3c5593fe70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "    string name = 1;\n",
    "    int32 id = 2;\n",
    "    repeated string email = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d1d0a-939f-48c2-89f0-5a9313277369",
   "metadata": {},
   "source": [
    "And let's compile it (the `--descriptor_set_out` and `--include_imports` options are only required for the `tf.io.decode_proto()` example below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74b294c-3f69-4671-9aa5-c5df3ec16be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27dd7b54-cdf1-45fd-a1cc-824abed56e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person.desc  person_pb2.py  person.proto\n"
     ]
    }
   ],
   "source": [
    "!ls person*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f97eb0e-5280-4be5-a06e-fe07320b22fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"Al\"\n",
       "id: 123\n",
       "email: \"a@b.com\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from person_pb2 import Person # import the generated access class\n",
    "\n",
    "person = Person(name=\"Al\", id=123, email=[\"a@b.com\"]) #create a person\n",
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f56530b7-3bae-4d1a-9c74-c1168606261f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Al'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person.name # read name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ccef13c-f513-4a99-8b1f-e2eec09b2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.name = \"Alice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b29057e-bede-4c63-91a6-62513fb1ad9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"Alice\"\n",
       "id: 123\n",
       "email: \"a@b.com\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "769b8df4-160d-4466-b658-b034a29bdcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a@b.com'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person.email[0] # repeated fields can be accessed like arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9040aa7-149b-456b-8473-e9eb637e0daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "person.email.append(\"c@d.com\") # add an email add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e59e48c3-bf53-4fc8-897c-ed901d4e8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = person.SerializeToString() # serialize object to a byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3043823-7acf-4d5a-87ae-5f7b9a08f6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x05Alice\\x10{\\x1a\\x07a@b.com\\x1a\\x07c@d.com'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "039acad1-e9f4-41d0-85e7-11b79bfa1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "person2 = Person() # create a new person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cb63ba2-d44c-405d-8263-6adde5d78747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person2.ParseFromString(s) # parse the byte string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a21687-0fab-4761-89ca-2e4cf69cdc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person == person2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad6d27-5c22-4135-8fd4-8425953179a9",
   "metadata": {},
   "source": [
    "The serialized data `s` is the binary data that is ready to be saved or transmitted over the network. When reading or receiving this binary data, we can parse it using the `ParseFromString()` method, and we get a copy of the object that was serialized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e10e5-f4d2-4584-ac2b-e70fb8e879e2",
   "metadata": {},
   "source": [
    "### TensorFlow Protobufs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62df8a1-2e95-41b7-8d1b-d73102c6fbf8",
   "metadata": {},
   "source": [
    "TF include special protobuf definitons for which it provides parsing operations. \n",
    "\n",
    "The main protobuf typically used in TFRecord file is the `Example` protobuf, which represents one instance in a dataset. It contains a list of named features, where each feature can be either a list of byte strings, a list of floats, or a list of integers. Here's the protobuf definition:\n",
    "\n",
    "```\n",
    "syntax = \"proto3\";\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
    "message Feature {\n",
    "    oneof kind {\n",
    "        BytesList bytes_list = 1;\n",
    "        FloatList float_list = 2;\n",
    "        Int64List int64_list = 3;\n",
    "    }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1; };\n",
    "message Example { Features features = 1; };\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1369d26-f9cb-42d6-b772-0a201f16f4ca",
   "metadata": {},
   "source": [
    "`[packed = true]` is used for repeated numerical fields, for more efficient encoding. A `Feature` contains either a `BytesList`, a `FloatList` or an `Int64List`. A `Features` (with a `s`) contains a dictionary that maps a feature name to the corresponding feature value. \n",
    "\n",
    "Here's how we could create a `tf.train.Example` representing the same person as earlier and write it to a TFRecord file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a65c9162-039d-4d6e-ab5c-c1202379099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "person_example = Example(features=Features(\n",
    "                        feature = {\n",
    "                            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "                            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "                            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", \n",
    "                                                                         b\"c@d\"]))\n",
    "                        }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae95d6-6d65-4dcf-9b19-ab54f082cd46",
   "metadata": {},
   "source": [
    "Now, we have a `Example` protobuf, we can serialize it by calling its `SerializeToString()` method, then write the resulting data to a `TFRecord` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eceec33d-a92f-4e2a-9d32-a51c964ac035",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cd790-79b3-400e-8136-186b09482de8",
   "metadata": {},
   "source": [
    "Normally we would write much more than one `Example!` Typically, we would create a conversion script that reads from our current format (say, CSV files), creates an `Example` protobuf for each instance, serializes them, and save them to several TFRecord files, ideally shuffling them in the process. This requires a bit of work, so once again make sure it is really necessary.\n",
    "\n",
    "Now that we have a nice TFRecord file containing a serialized `Example`, let's try to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c880636-75c1-4a1d-ba30-088f4aaca127",
   "metadata": {},
   "source": [
    "## Loading and Parsing Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da1eeb-83b5-4da2-bcc5-1dbf8ffebf11",
   "metadata": {},
   "source": [
    "To load the serialized `Examples` protobufs, we will use a `tf.data.TFRecordDataset` once again, and we will parse each `Example` using `tf.io.parse_single_example()`. This is TF operation. It requires at least two arguments: a string scaler tensor containing a serialized data, and a description of each feature. The description is a dictionary that maps each feature name to either a `tf.io.FixedLenFeature` descriptor indicating the feature's shape, type and a default value, or a `tf.io.VarLenFeature` descriptor indicating only the type (if the length of feature's list may vary, such as for the `\"emails\"` feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cbeb2e-45e6-4a6e-9d1f-948c2258df40",
   "metadata": {},
   "source": [
    "The following code defines a description dicitonary, then it iterates over the `TFRecordDataset` and parses the serialized `Example` protobuf this dataset contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9675a366-90d9-4856-923c-845ca5bb6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c0d90db-153b-4359-9758-b7297d4782eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emails': SparseTensor(indices=tf.Tensor(\n",
       " [[0]\n",
       "  [1]], shape=(2, 1), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d'], shape=(2,), dtype=string), dense_shape=tf.Tensor([2], shape=(1,), dtype=int64)),\n",
       " 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n",
       " 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca82bdb-beaa-4fa3-abbd-535f310dc3bc",
   "metadata": {},
   "source": [
    "The fixed length features are paresed as regular tensors, but the variable-length features are parsed as sparse tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b08b12df-3c62-4e2d-9631-e33436fb2b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'a@b.com'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9c897c-283d-4255-b87e-43234e5b666f",
   "metadata": {},
   "source": [
    " We can convert a sparse tensor to a dense tensor using `tf.sparse.to_dense()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b7bb19b-119f-4dab-8088-6e8c8ba411cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d'], dtype=object)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8f0b405-bb22-4dec-a7d8-57469e734696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d'], dtype=object)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71992274-675a-4f03-a126-91ebb97c3d70",
   "metadata": {},
   "source": [
    "A `BytesList` can contain any binary data we want, including any serialized object. For eg: we can use `tf.io.encode_jpeg()` to encode an image using the JPEG format and put this binary data in a `BytesList`. Later, when our code reads the `TFRecord`, it will start by parsing the `Example`, then it will need to call `tf.io.decode_jpeg()` to parse the data and get the original image.\n",
    "\n",
    "We can also store any tensor we want in `ByteList` by serializing the tensor using `tf.io.serialize_tensor()` then putting the resulting byte string in a `ByteList` feature. Later, when we parse the TFRecord, we can parse this data using `tf.io.parse_tensor()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18637689-07e8-47ed-ba96-b9804b52325c",
   "metadata": {},
   "source": [
    "Instead of parsing examples one by one using `tf.io.parsing_single_example()`, we may want to parse them batch by batch using `tf.io.parse_example()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34f5eeb-9e40-4723-a8a8-78beec9c9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(10)\n",
    "for serialized_example in dataset:\n",
    "    parsed_examples = tf.io.parse_example(serialized_example, feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79087bcb-1476-4afa-8a87-e936c7843779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emails': SparseTensor(indices=tf.Tensor(\n",
       " [[0 0]\n",
       "  [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64)),\n",
       " 'id': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([123])>,\n",
       " 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Alice'], dtype=object)>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f96e1-bde5-45c9-b34c-159c6625ad60",
   "metadata": {},
   "source": [
    "`Example` protobuf will be sufficiently for most of the cases. But it may be cumbersome to use when we are dealing with lists of lists. `SequenceExample` protobuf is designed for such use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851b551d-4882-4fa3-9ed8-0be596f97290",
   "metadata": {},
   "source": [
    "## Handling Lists of Lists Using the SequenceExample Protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c5297-1ad3-4635-87fc-11f15955fdd6",
   "metadata": {},
   "source": [
    "Here's the definition of the `SequenceExample` protobuf:\n",
    "```\n",
    "message FeatureList { repeated Feature feature = 1; };\n",
    "message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
    "message SequenceExample {\n",
    "    Features context = 1;\n",
    "    FeatureLists feature_lists = 2;\n",
    "};\n",
    "```\n",
    "\n",
    "A `SequenceExample` contains a `Features` object for the contextual data and a `FeatureLists` object that contains one or more named `FeatureList` objects (e.g., a `FeatureList` named `\"content\"` and another named `\"comments\"`). Each `FeatureList` contains a list of `Feature` objects, each of which may be a list of byte strings, a list of 64-bit integers, or a list of floats (in this example, each `Feature` would represent a sentence or a comment, perhapds in the form of list of word identifiers). Building a `SequenceExample`, serializing it, and parsing it is similar to building, serializing, and parsing an `Example`, but we must use `tf.io.parse_single_sequence_example()` to parse a single `SequeneExample` or `tf.io.parse_sequence_example()` to parse a batch. Both functions return a tuple containing the context features (as a dictionary) and the feature lists (also a dictionary). If the feature lists contain sequences of varying sizes, we may want to convert them to ragged tensors, using `tf.RaggedTensor.from_sparse()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "875b3fef-1519-46bd-b31b-d7a0bf308599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import FeatureList, FeatureLists, SequenceExample, Features, Feature\n",
    "from tensorflow.train import BytesList, Int64List\n",
    "\n",
    "context = Features(feature={\n",
    "    \"author_id\": Feature(int64_list=Int64List(value=[123])),\n",
    "    \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"desert\", b\"place\", b\".\"])),\n",
    "    \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25]))\n",
    "})\n",
    "\n",
    "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"],\n",
    "          [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
    "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"],\n",
    "           [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
    "\n",
    "def words_to_feature(words):\n",
    "    return Feature(bytes_list=BytesList(value=[word.encode(\"utf-8\") for word in words]))\n",
    "\n",
    "content_features = [words_to_feature(sentence) for sentence in content]\n",
    "comment_features = [words_to_feature(comment) for comment in comments]\n",
    "\n",
    "sequence_example = SequenceExample(\n",
    "        context=context,\n",
    "        feature_lists=FeatureLists(feature_list={\n",
    "            \"content\": FeatureList(feature=content_features),\n",
    "            \"comments\": FeatureList(feature=comment_features)\n",
    "        })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f21a033-3386-476d-82bf-08e03e737ae1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "context {\n",
       "  feature {\n",
       "    key: \"title\"\n",
       "    value {\n",
       "      bytes_list {\n",
       "        value: \"A\"\n",
       "        value: \"desert\"\n",
       "        value: \"place\"\n",
       "        value: \".\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"pub_date\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 1623\n",
       "        value: 12\n",
       "        value: 25\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature {\n",
       "    key: \"author_id\"\n",
       "    value {\n",
       "      int64_list {\n",
       "        value: 123\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature_lists {\n",
       "  feature_list {\n",
       "    key: \"content\"\n",
       "    value {\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"When\"\n",
       "          value: \"shall\"\n",
       "          value: \"we\"\n",
       "          value: \"three\"\n",
       "          value: \"meet\"\n",
       "          value: \"again\"\n",
       "          value: \"?\"\n",
       "        }\n",
       "      }\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"In\"\n",
       "          value: \"thunder\"\n",
       "          value: \",\"\n",
       "          value: \"lightning\"\n",
       "          value: \",\"\n",
       "          value: \"or\"\n",
       "          value: \"in\"\n",
       "          value: \"rain\"\n",
       "          value: \"?\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  feature_list {\n",
       "    key: \"comments\"\n",
       "    value {\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"When\"\n",
       "          value: \"the\"\n",
       "          value: \"hurlyburly\"\n",
       "          value: \"\\'s\"\n",
       "          value: \"done\"\n",
       "          value: \".\"\n",
       "        }\n",
       "      }\n",
       "      feature {\n",
       "        bytes_list {\n",
       "          value: \"When\"\n",
       "          value: \"the\"\n",
       "          value: \"battle\"\n",
       "          value: \"\\'s\"\n",
       "          value: \"lost\"\n",
       "          value: \"and\"\n",
       "          value: \"won\"\n",
       "          value: \".\"\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3936aad-11ed-4415-8385-4c64f3ddc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_sequence_example = sequence_example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3ae531-1455-42b9-8d50-4cff4358bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_descriptions = {\n",
    "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"title\": tf.io.VarLenFeature(tf.string),\n",
    "    \"pub_data\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0,0,0])\n",
    "}\n",
    "\n",
    "sequence_feature_descriptions = {\n",
    "    \"content\": tf.io.VarLenFeature(tf.string),\n",
    "    \"comments\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    "    serialized_sequence_example, context_feature_descriptions, sequence_feature_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b1f20bc-07ca-419b-8b42-49112187de54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': SparseTensor(indices=tf.Tensor(\n",
       " [[0]\n",
       "  [1]\n",
       "  [2]\n",
       "  [3]], shape=(4, 1), dtype=int64), values=tf.Tensor([b'A' b'desert' b'place' b'.'], shape=(4,), dtype=string), dense_shape=tf.Tensor([4], shape=(1,), dtype=int64)),\n",
       " 'author_id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n",
       " 'pub_data': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 0])>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7db78b1e-46b5-4e24-83c6-ab48c812e797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'A', b'desert', b'place', b'.'], dtype=object)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_context[\"title\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02229416-086d-4d0b-afe8-c9647d08d9d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': SparseTensor(indices=tf.Tensor(\n",
       " [[0 0]\n",
       "  [0 1]\n",
       "  [0 2]\n",
       "  [0 3]\n",
       "  [0 4]\n",
       "  [0 5]\n",
       "  [1 0]\n",
       "  [1 1]\n",
       "  [1 2]\n",
       "  [1 3]\n",
       "  [1 4]\n",
       "  [1 5]\n",
       "  [1 6]\n",
       "  [1 7]], shape=(14, 2), dtype=int64), values=tf.Tensor(\n",
       " [b'When' b'the' b'hurlyburly' b\"'s\" b'done' b'.' b'When' b'the' b'battle'\n",
       "  b\"'s\" b'lost' b'and' b'won' b'.'], shape=(14,), dtype=string), dense_shape=tf.Tensor([2 8], shape=(2,), dtype=int64)),\n",
       " 'content': SparseTensor(indices=tf.Tensor(\n",
       " [[0 0]\n",
       "  [0 1]\n",
       "  [0 2]\n",
       "  [0 3]\n",
       "  [0 4]\n",
       "  [0 5]\n",
       "  [0 6]\n",
       "  [1 0]\n",
       "  [1 1]\n",
       "  [1 2]\n",
       "  [1 3]\n",
       "  [1 4]\n",
       "  [1 5]\n",
       "  [1 6]\n",
       "  [1 7]\n",
       "  [1 8]], shape=(16, 2), dtype=int64), values=tf.Tensor(\n",
       " [b'When' b'shall' b'we' b'three' b'meet' b'again' b'?' b'In' b'thunder'\n",
       "  b',' b'lightning' b',' b'or' b'in' b'rain' b'?'], shape=(16,), dtype=string), dense_shape=tf.Tensor([2 9], shape=(2,), dtype=int64))}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_feature_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11baec-b50a-4bc4-a700-103dd6faa5ff",
   "metadata": {},
   "source": [
    "## Preprocessing the Input Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e092c36-7ac8-49e9-ac00-afdb334aedc7",
   "metadata": {},
   "source": [
    "Preprocessing can be done ahead of time when preparing our data files, using any tools like (e.g., Numpy, pandas or scikit-learn). Alternatively we can preprocess the data on the fly when loading it using the Data API (e.g., using the `map()` method), or we can include preprocessing layer directly into our model. \n",
    "\n",
    "Now let's look at last option. Here's how we can implement a standardization layer using a `Lambda` layer. For each layer, it subtracts the mean and divide by its standard deviation (plus a tiny smoothing term to avoid division by zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cfd4e6f-f6fc-4ae0-8a98-9e6e550ba8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(X_train, axis=0, keepdims=True)\n",
    "stds = np.std(X_train, axis=0, keepdims=True)\n",
    "eps = keras.backend.epsilon()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Lambda(lambda inputs: (inputs - means) / (stds + eps))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d824012-5451-4857-8636-ca3b1d178191",
   "metadata": {},
   "source": [
    "That's not too hard! However, we may prefer to use a nice self-contained custom layer, rather than having global variables like `means` and `stds` dangling around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20eead3f-3677-4554-9dc3-12b9189c7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc88608-f0da-4365-a282-f31829ab8e19",
   "metadata": {},
   "source": [
    "Before we can use this Standardization layer, we will need to adapt it to our dataset by calling the `adapt()` method and passing it a data sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b17f9b-7c7e-4a60-82a5-392690b7fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_layer = Standardization()\n",
    "std_layer.adapt(data_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01933b54-eefd-4a40-8d6d-1941b3e4b2ec",
   "metadata": {},
   "source": [
    "This sample must be large enough to be representative of our dataset, but it does not have to be the full training set: in general, a few hundered randomly selected instances will suffice. Now we can use this preprocessing layer like a normal layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dd7bfdc-a0f8-4764-9762-e0d20ca468e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ellipsis]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(std_layer)\n",
    "[...] # other layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55c353-3d76-40f7-9ea8-3a781800cd0f",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features Using One-Hot Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1cf5a8-94bc-448b-bbb5-dc9281f35f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                  41          880           129.0   \n",
       "1    -122.22     37.86                  21         7099          1106.0   \n",
       "2    -122.24     37.85                  52         1467           190.0   \n",
       "3    -122.25     37.85                  52         1274           235.0   \n",
       "4    -122.25     37.85                  52         1627           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0         322         126         8.3252              452600        NEAR BAY  \n",
       "1        2401        1138         8.3014              358500        NEAR BAY  \n",
       "2         496         177         7.2574              352100        NEAR BAY  \n",
       "3         558         219         5.6431              341300        NEAR BAY  \n",
       "4         565         259         3.8462              342200        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv(\"datasets/housing/housing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d51e5-dfe9-40b3-8714-2e6ae31279f7",
   "metadata": {},
   "source": [
    "Consider the `ocean_proximity` feature in the above dataset: it is a categorical feature with five possible values. We need to encode this feature before we feed it to a neural network. Since there are very few categories, we can use one-hot encoding. For this, we need to map each category to its index (0 to 4), which can be done using a lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05886bd6-a7b4-45df-bf6a-c306345f4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first define the vocalubary: this is list of all possible categories.\n",
    "vocab = [\"<1H Ocean\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "# then we create a tensor with corresponding indices (0 to 4)\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "# next we create an initializer for the lookup table, passing the list of categories and their corresponding indices. Here we already had data, so we used `KeyValueTensorInitializer`; but if the categories were listed in a text file (with one category per line), we would use `TextFileInitializer` instead. \n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "# in last two lines we create the lookup table, giving the initializer and specifying the number of `out-of-vocabulary` (oov) buckets. If we lookup a category that does not exists in the vocabulary, the lookup table will compute the hash of this category and use it to assign the unkown category to one of the oov buckets. Their indices start after the known categories, so in this example the indices of two oov buckets are 5 and 6.\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f31661a-de95-4be8-a748-c6150525bc2f",
   "metadata": {},
   "source": [
    "Let's use the lookup table to encode a small batch of categorical features to one-hot vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dde08959-e484-44cb-b0e0-48ff72844b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2414e0f-f0e3-47f0-a41b-2533fe8033bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaebda02-f2f6-429a-8104-b8b92d43b869",
   "metadata": {},
   "source": [
    "As we can see that `\"NEAR BAY\"` was mapped to index 3, the unkown category `\"DESERT\"` was mapped to one of the two oov buckets (at index 5). Then we use `tf.one_hot()` to one-hot encode these indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d3475-334f-45bb-9930-bef159fb25e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc9ae76-cab0-437d-a2ef-91d12ad18b26",
   "metadata": {},
   "source": [
    "This may not be the best solution, though. The size of each one-hot vector is the vocabulary length plus the number of oov buckets. This is fine when there are just few possible categories, but if the vocabulary is large, it is much more efficient to encode them using the `embeddings` instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c419d-a3e2-4f01-b092-18984b1d54b1",
   "metadata": {},
   "source": [
    "### Encoding Categorical Features Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb11ec-dede-4368-8b53-247ddd75db66",
   "metadata": {},
   "source": [
    "Let's look at how we could implement embeddings manually, to understand how they work (then we will use a simple Keras Layer instead).\n",
    "\n",
    "First we need to create an *embedding matrix* containing each category's embeddings, initialized randomly; it will have one row per category and per oov, and one column per embedding dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e975e29-7ab9-4575-af9d-42a4d4ab29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f2772-c86c-4a2b-94b1-d68266bad40d",
   "metadata": {},
   "source": [
    "In this example we are using 2D embeddings, but as a rule of thumb embeddings typically have 10 to 300 dimensions, depending upon task and the vocab size (we will need to tune this hyperparameter).\n",
    "\n",
    "This embedding matrix is a 6x2 matrix, stored in a variable (so it can be tweaked by GD during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6758849d-d99e-49ce-b12f-76de4f0c5ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84811795, 0.46585   ],\n",
       "       [0.18549359, 0.10970199],\n",
       "       [0.7764783 , 0.5948725 ],\n",
       "       [0.35267866, 0.7569587 ],\n",
       "       [0.56747866, 0.66905403],\n",
       "       [0.6271386 , 0.29577494],\n",
       "       [0.07407355, 0.8167274 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2307e-3005-4d8d-ad76-8cb6574e67d3",
   "metadata": {},
   "source": [
    "Now let's encode the same batch of categorical features as earlier, but this time using these embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99890f5d-74c9-46fc-8730-3b01d6db18f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "614b6801-2937-465a-af5f-06fd9fc584ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.35267866, 0.7569587 ],\n",
       "       [0.6271386 , 0.29577494],\n",
       "       [0.18549359, 0.10970199],\n",
       "       [0.18549359, 0.10970199]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac346c7-8e63-42e6-b5b5-ff6df71ff64a",
   "metadata": {},
   "source": [
    "The `tf.nn.embedding_lookup()` function looks up the rows in the embedding matrix, at the given indices - that's all it does. For eg., the lookup table says that the `\"INLAND\"` category is at index `1`, so the `tf.nn.embedding_lookup()` function returns the embedding row at 1 in the embedding matrix matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87114db-fdd2-4dfe-a994-c059ece260e3",
   "metadata": {},
   "source": [
    "Keras provides a `keras.layers.Embedding` layer that handles the embedding matrix (trainable, by default); when the layer is created it initializes the embedding matrix randomly, and then when it is called with some category indices it returns the rows at those indices in the embedding matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f9f22f3-531e-40f3-b23c-6a4ebae124d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets, output_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb07ef9c-48a0-4ee7-a530-60eaf9266153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-0.03308481,  0.03021936],\n",
       "       [ 0.02696408, -0.04613159],\n",
       "       [-0.02853929, -0.02763538],\n",
       "       [-0.02853929, -0.02763538]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20c8a2-76dc-44e8-abb6-657ed74a1ba6",
   "metadata": {},
   "source": [
    "Putting everything together, we can now create a Keras model that can process categorical features (along with numerical features) and learn an embedding for each category (as well as for each oov bucket):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4a9992f-da3c-4c25-8688-e11720aed0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469ec72-7124-4b2e-9626-5b8a3f80e657",
   "metadata": {},
   "source": [
    "### Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7036686-dde6-414e-bc0d-80941811bc56",
   "metadata": {},
   "source": [
    "## TF Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70350c2b-8137-495b-8c8e-4b6ce07b2523",
   "metadata": {},
   "source": [
    "## The TensorFlow DataSets (TFDS) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5b094-5d5f-43f9-8865-a1393d510bf5",
   "metadata": {},
   "source": [
    "Let's load MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a8a232-ecf1-4c1a-af18-40fdaaaaa934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500f6c8-6f10-43b5-a13d-4fbac520fd42",
   "metadata": {},
   "source": [
    "Then we can apply any transformation we want (typically shuffling, batching and prefetching), and we're ready to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f47586-ce76-457e-9e7a-da5732e6d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "    images = item[\"image\"]\n",
    "    labels = item[\"label\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386030d8-133b-40dc-aaf1-d118b70c3efd",
   "metadata": {},
   "source": [
    "Note that each item in the dataset is a dictionary containing both the features and the labels. But Keras expects each item to be a tuple containing two elements (again, the features and the labels). We could transform the dataset using the `map()` method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7fded9-7a2e-4425-b350-f32659963332",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0136228-38c8-4a5f-8c98-53bde2ffbf56",
   "metadata": {},
   "source": [
    "But it's simpler to ask the `load()` function to do this for us by setting `as_supervised=True`. We can also specify the batch size if we want. Then we can pass the dataset directly to our tf.keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0369941-f8ff-4684-8ec4-10f7dcec70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "mnist_train = dataset[\"train\"].prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677d302f-9101-45ae-b317-5628c6023ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 32.0839 - accuracy: 0.8421\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 820us/step - loss: 25.8106 - accuracy: 0.8697\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 824us/step - loss: 25.1705 - accuracy: 0.8738\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 856us/step - loss: 24.1452 - accuracy: 0.8760\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 874us/step - loss: 23.9523 - accuracy: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f4f83fefd10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28,1]),\n",
    "    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a735a-70fe-497b-bb6e-43c6d6614b0a",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e82322-049e-458c-8ea1-17e66f6fd5f3",
   "metadata": {},
   "source": [
    "### 9.\n",
    "\n",
    "#### a. \n",
    "\n",
    "Load the Fashion MNIST dataset; split\n",
    "it into a training set, a validation set, and a test set; shuffle the\n",
    "training set; and save each dataset to multiple TFRecord files.\n",
    "Each record should be a serialized Example protobuf with two\n",
    "features: the serialized image (use tf.io.serialize_tensor()\n",
    "to serialize each image), and the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20851cdb-632e-49bd-9534-158da13fa0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5590959f-e12f-447a-a89a-001de4dc5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75f753aa-03f6-41a8-a522-99ae31422f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64299373-2068-4356-9d46-78ca9b67951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import Example, Features, Feature, BytesList, Int64List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f49eaa-c773-4ad1-b64e-607e9edcd6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84f089e8-a83d-4d9a-8ca1-4746ef82b3b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe9319-ede3-476f-80e7-8c6324dba7dd",
   "metadata": {},
   "source": [
    "The following function saves a given dataset to a set of TFRecord files. The example are written to the files in the round-robin fashion. To do this, we enumerate all the examples using `dataset.enumerate()` method, and compute `index % n_shards` to decide which file to write to. We use the `contextlib.ExitStack` class to make sure that all writers are properly closed whether or not an I/O error occurs while writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3843e41-25cf-4460-8b06-6f74e4deca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "base_path = \"datasets/fashion_mnist_tfrecords/\"\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    name = base_path + name\n",
    "    paths=[\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards) for index in range(n_shards)]\n",
    "    \n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path)) for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e2415fd-659c-41b5-ba1c-c545ee0d0fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 22:34:41.759852: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-01-11 22:35:15.445097: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-01-11 22:35:18.830899: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    }
   ],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77904b19-e646-4a6b-a63b-a6da04cc0330",
   "metadata": {},
   "source": [
    "#### b. \n",
    "\n",
    "Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to\n",
    "train these datasets, including a preprocessing layer to standardize\n",
    "each input feature. Try to make the input pipeline as efficient as\n",
    "possible, using TensorBoard to visualize profiling data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "980a275f-9d09-4dfb-9699-3cbaca244b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aed2efcc-d078-445d-90bb-e905c242be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None, \n",
    "                 n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "    \n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39e809e9-c379-4402-9dc8-cc66771f7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "753b7c13-0fda-4e15-a325-cd54a3b068a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a360515d-bf17-48a7-8891-a3e01df6cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "586450e7-a8d4-46fb-85d9-7dd812ed0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = Standardization(input_shape=[28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae820087-dbc1-4e44-96ff-bfcee3e35bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()), \n",
    "                              axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84ca791e-9179-47bb-baf9-f7c46617ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f3930c4-37f4-47df-b064-b02fc42c0c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 22:51:00.202237: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-11 22:51:00.202265: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-01-11 22:51:00.203181: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     88/Unknown - 2s 2ms/step - loss: 0.8829 - accuracy: 0.7180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 22:51:01.666139: I tensorflow/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-01-11 22:51:01.666171: I tensorflow/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-01-11 22:51:01.669865: I tensorflow/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-01-11 22:51:01.677426: I tensorflow/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-01-11 22:51:01.677781: I tensorflow/tsl/profiler/rpc/client/save_profile.cc:144] Collecting XSpace to repository: ./my_logs/run_20240111_225100/plugins/profile/2024_01_11_22_51_01/ubuntu.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.4731 - accuracy: 0.8395 - val_loss: 0.4279 - val_accuracy: 0.8702\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3488 - accuracy: 0.8784 - val_loss: 0.5630 - val_accuracy: 0.8576\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3110 - accuracy: 0.8907 - val_loss: 0.4203 - val_accuracy: 0.8770\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2843 - accuracy: 0.8987 - val_loss: 0.3877 - val_accuracy: 0.8816\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2602 - accuracy: 0.9065 - val_loss: 0.4210 - val_accuracy: 0.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6842317c50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "logs = os.path.join(os.curdir, \"my_logs\", \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set, callbacks=[tensorboard_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest)",
   "language": "python",
   "name": "latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
